{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cLswalyHXSie"
   },
   "outputs": [],
   "source": [
    "# è¡›æ˜Ÿå½±åƒåˆ¤é‡‹æ°´åŸŸè¦†è“‹ç‡å…¬é–‹ç¨‹å¼ç¢¼\n",
    "# - - - - - - - - - - -\n",
    "\"\"\"\n",
    "ç”¨æ–¼å°ç£æœ¬å³¶ç¯„åœä¹‹ç›£æ¸¬ç¯„åœæ°´åŸŸè¦†è“‹ç‡ä¼°ç®—ã€‚\n",
    "\"\"\"\n",
    "# å…§å®¹\n",
    "# - - - - - - - - - - -\n",
    "\"\"\"\n",
    "Part 1 - ä¸‹è¼‰è¡›æ˜Ÿå½±åƒ\n",
    "> è¡›æ˜Ÿå½±åƒåƒæ•¸ï¼š\n",
    "    \"type\": \"sentinel-1-grd\",\n",
    "    \"Operational mode\": \"IW\",\n",
    "    \"Resolution\": \"HIGH\",\n",
    "    \"Polarization\": \"DV\",\n",
    "    \"Orbit Direction\": \"DESCENDING\",\n",
    "    \"Polarisation channels\"ï¼š\"VV\",\"VH\"\n",
    "> å½±åƒé è™•ç†ï¼š\n",
    "  \"backCoeff\": \"GAMMA0_TERRAIN\",\n",
    "  \"orthorectify\": \"true\",\n",
    "  \"demInstance\": \"COPERNICUS\",\n",
    "  \"radiometricTerrainOversampling\": 2\n",
    "\n",
    "Part 2 - æ¥åˆå½±åƒ\n",
    "å¦‚æœç›£æ¸¬ç¯„åœå¯¬ã€é«˜å¤§æ–¼25å…¬é‡Œï¼Œå¿…é ˆå°‡å½±åƒåˆ‡å‰²å¾Œï¼Œæ–¹èƒ½ä¸‹è¼‰ã€‚\n",
    "è‹¥æ¨£å€å¯èƒ½é­è£åˆ‡æ–¼å¤šå¼µå½±åƒä¸­ï¼Œå°‡é€ æˆå¾ŒçºŒæ°´åŸŸè¨ˆç®—æœ‰èª¤ï¼Œå»ºè­°å°‡å½±åƒæ¥åˆå¾Œæ–¹èƒ½é€²è¡Œé‹ç®—ã€‚\n",
    "\n",
    "Part 3 - æ°´åŸŸè¦†è“‹ç‡åˆ¤é‡‹\n",
    "> æ°´åŸŸåˆ¤é‡‹æ¥µåŒ–ï¼šVV\n",
    "> æ°´åŸŸåˆ¤é‡‹æ•¸ä½æ•¸å€¼é–¾å€¼ï¼š0.029\n",
    "\"\"\"\n",
    "# æé†’\n",
    "# - - - - - - - - - - -\n",
    "\"\"\"\n",
    "*** è«‹å°‡ç¨‹å¼ç¢¼è¤‡è£½ä¸€ä»½è‡³æ–°çš„colabé é¢åŸ·è¡Œ\n",
    "*** è‹¥è©²æ®µè½ç¨‹å¼ç¢¼åŸ·è¡Œæ™‚é–“éé•·ï¼Œè«‹å˜—è©¦å°‡è©²æ®µè½åˆ‡åˆ†æˆå¤šæ®µä¾åºåŸ·è¡Œ ***\n",
    "*** è‹¥ç„¡éœ€å°‡æ¯å€‹æ¨£å€ä¹‹saråœ–å±¤åˆ†åˆ¥å­˜å–ï¼Œç›¡é‡å°‡ç›£æ¸¬ç¯„åœæ¶µè“‹æ–¼å–®ä¸€polygonä¸­ä¸‹è¼‰è¡›æ˜Ÿå½±åƒï¼Œé¿å…å„æ¨£å€å½±åƒé‡ç–Šï¼Œå½±éŸ¿è¦†è“‹ç‡è¨ˆç®— ***\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 96326,
     "status": "ok",
     "timestamp": 1762162283604,
     "user": {
      "displayName": "mickey Wu",
      "userId": "17857565069847384916"
     },
     "user_tz": -480
    },
    "id": "ON_v-eVCdaZY",
    "outputId": "58405def-87c1-40b4-a325-d5c82de93930"
   },
   "outputs": [],
   "source": [
    "# @title Part 1 - Sentinel-1 è¡›æ˜Ÿå½±åƒä¸‹è¼‰\n",
    "\n",
    "# === é€£æ¥ Google Drive ===\n",
    "\"\"\"\n",
    "æˆ‘å€‘ä½¿ç”¨ Google Drive ä½œç‚ºè¡›æ˜Ÿå½±åƒåŠåœ°ç†ç©ºé–“è³‡è¨Šå­˜å–è·¯å¾‘ï¼Œ\n",
    "æ•…é ˆå…ˆé€£çµä½¿ç”¨è€…Google Driveå¸³è™Ÿä»¥åŸ·è¡Œå¾ŒçºŒä½œæ¥­ã€‚\n",
    "\"\"\"\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive', force_remount=True)\n",
    "\n",
    "\n",
    "# === è¼‰å…¥æ‰€éœ€å¥—ä»¶ ===\n",
    "import os, json, requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from datetime import datetime, timedelta\n",
    "from pyproj import Transformer\n",
    "from oauthlib.oauth2 import BackendApplicationClient\n",
    "from requests_oauthlib import OAuth2Session\n",
    "\n",
    "\n",
    "# === Copernicus OAuth é©—è­‰ ===\n",
    "\"\"\"\n",
    "è«‹å…ˆæ–¼ Copernicus Data Space Ecosystem å®˜ç¶²è¨»å†Š OAuth clientï¼Œ\n",
    "ä¸¦å°‡ client_idã€client_secret å¡«å…¥ä¸‹æ–¹ã€‚\n",
    "è©³ç´°æ“ä½œæ–¹æ³•ï¼š\n",
    "https://documentation.dataspace.copernicus.eu/APIs/SentinelHub/Overview/Authentication.html#python\n",
    "\"\"\"\n",
    "\n",
    "def loadtoken():\n",
    "  # Your client credentials\n",
    "  client_id = 'client_id' # change to your client_id\n",
    "  client_secret = 'secret'   # change to your secret\n",
    "\n",
    "  try:\n",
    "      # Create a session\n",
    "      client = BackendApplicationClient(client_id=client_id)\n",
    "      oauth = OAuth2Session(client=client)\n",
    "\n",
    "      # Get token for the session\n",
    "      token = oauth.fetch_token(token_url='https://identity.dataspace.copernicus.eu/auth/realms/CDSE/protocol/openid-connect/token',\n",
    "                                client_secret=client_secret, include_client_id=True)\n",
    "\n",
    "      # All requests using this session will have an access token automatically added\n",
    "      resp = oauth.get(\"https://sh.dataspace.copernicus.eu/configuration/v1/wms/instances\")\n",
    "      print(\"âœ… Copernicus OAuth é©—è­‰æˆåŠŸ\")\n",
    "      return oauth\n",
    "  except Exception as e:\n",
    "      print(f\"âŒ Copernicus é©—è­‰å¤±æ•—ï¼š{e}\")\n",
    "      raise\n",
    "\n",
    "\n",
    "# === åˆ‡æ›å·¥ä½œç›®éŒ„ ===\n",
    "\"\"\"\n",
    "å°‡æ¬²å­˜æ”¾è¡›æ˜Ÿå½±åƒçš„ Google Drive è³‡æ–™å¤¾è·¯å¾‘è¨­ç‚ºæ–°çš„ç›®éŒ„\n",
    "\"\"\"\n",
    "geotiff_path = 'è¡›æ˜Ÿå½±åƒå­˜æ”¾è·¯å¾‘'\n",
    "os.makedirs(geotiff_path, exist_ok=True)\n",
    "os.chdir(geotiff_path)\n",
    "\n",
    "\n",
    "# === å®šç¾©ä¸‹è¼‰å½±åƒåƒæ•¸ ===\n",
    "\"\"\"\n",
    "ä¿®æ”¹å¯åƒè€ƒï¼š\n",
    "https://docs.sentinel-hub.com/api/latest/reference/\n",
    "https://documentation.dataspace.copernicus.eu/APIs/SentinelHub/Process/Examples/S1GRD.html#s1grd-orthorectified-linear-gamma0-vv-between-0-and-05-in-approximate-real-world-10-m-resolution-iw-png\n",
    "\"\"\"\n",
    "def requestdata(polygon, target, width, height, dt_obj, outputformat=\"image\"):\n",
    "    dt_obj_end = dt_obj + timedelta(days=1)\n",
    "    url = \"https://sh.dataspace.copernicus.eu/api/v1/process\"\n",
    "\n",
    "    if outputformat == \"image\":\n",
    "        evalscript = \"\"\"\n",
    "        //VERSION=3\n",
    "        function setup() {\n",
    "          return {\n",
    "            input: [\"VV\",\"VH\"],\n",
    "            output: { id: \"default\", bands: 2, sampleType: SampleType.FLOAT32 }\n",
    "          }\n",
    "        }\n",
    "        function evaluatePixel(samples) {\n",
    "          return [samples.VV, samples.VH]\n",
    "        }\n",
    "        \"\"\"\n",
    "        responses = [{\"identifier\": \"default\", \"format\": {\"type\": \"image/tiff\"}}]\n",
    "        processing = {\n",
    "          \"backCoeff\": \"GAMMA0_TERRAIN\",\n",
    "          \"orthorectify\": \"true\",\n",
    "          \"demInstance\": \"COPERNICUS\",\n",
    "          \"radiometricTerrainOversampling\": 2\n",
    "        }\n",
    "    else:\n",
    "        evalscript = \"\"\"\n",
    "        //VERSION=3\n",
    "        function setup() {\n",
    "          return {\n",
    "            input: [\"VV\",\"VH\"],\n",
    "            output: { id: \"default\", bands: 2, sampleType: SampleType.FLOAT32 },\n",
    "            mosaicking: \"ORBIT\"\n",
    "          }\n",
    "        }\n",
    "        function evaluatePixel(samples) {\n",
    "          return [samples.VV, samples.VH]\n",
    "        }\n",
    "        function updateOutputMetadata(scenes, inputMetadata, outputMetadata) {\n",
    "          outputMetadata.userData = { \"scenes\": scenes.orbits }\n",
    "        }\n",
    "        \"\"\"\n",
    "        responses = [{\"identifier\": \"userdata\", \"format\": {\"type\": \"application/json\"}}]\n",
    "        processing = {}\n",
    "\n",
    "    payload = {\n",
    "        \"input\": {\n",
    "            \"bounds\": {\"geometry\": {\"type\": \"Polygon\", \"coordinates\": polygon}},\n",
    "            \"data\": [{\n",
    "                \"type\": \"sentinel-1-grd\",\n",
    "                \"dataFilter\": {\n",
    "                    \"timeRange\": {\n",
    "                        \"from\": dt_obj.strftime(\"%Y-%m-%dT%H:%M:%SZ\"),\n",
    "                        \"to\": dt_obj_end.strftime(\"%Y-%m-%dT%H:%M:%SZ\"),\n",
    "                    },\n",
    "                    \"acquisitionMode\": \"IW\",\n",
    "                    \"resolution\": \"HIGH\",\n",
    "                    \"polarization\": \"DV\",\n",
    "                    \"orbitDirection\": \"DESCENDING\"\n",
    "                },\n",
    "                \"processing\": processing\n",
    "            }]\n",
    "        },\n",
    "        \"output\": {\n",
    "            \"width\": width,\n",
    "            \"height\": height,\n",
    "            \"responses\": responses\n",
    "        },\n",
    "        \"evalscript\": evalscript\n",
    "    }\n",
    "\n",
    "    savepath = f\"{target}.tif\" if outputformat == \"image\" else f\"{target}.json\"\n",
    "\n",
    "    try:\n",
    "        headers = {\"Accept\": \"image/tiff\" if outputformat == \"image\" else \"application/json\"}\n",
    "        response = oauth.post(url, json=payload, headers=headers)\n",
    "        response.raise_for_status()\n",
    "\n",
    "        with open(savepath, 'wb') as f:\n",
    "            f.write(response.content)\n",
    "\n",
    "        print(f\"âœ… {savepath} ä¸‹è¼‰å®Œæˆ\")\n",
    "\n",
    "        if outputformat == \"json\":\n",
    "            metadata = response.json()\n",
    "            print(\"ğŸ“… å½±åƒæ—¥æœŸï¼š\", metadata['scenes'][0]['tiles'][0]['date'])\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸ ä¸‹è¼‰å¤±æ•—ï¼š{savepath}ï¼ŒåŸå› ï¼š{e}\")\n",
    "\n",
    "\n",
    "# === åŒ¯å…¥ç›£æ¸¬ç¯„åœ ===\n",
    "\"\"\"\n",
    "ä¸Šå‚³ GPKG æˆ– SHP ç›£æ¸¬ç¯„åœæª”æ¡ˆï¼Œ\n",
    "æª”æ¡ˆé ˆæœ‰ä¸€è­˜åˆ¥å„polygonçš„åç¨±æ¬„(å¦‚\"ID\"ã€\"name\")ï¼Œä½œç‚ºä¸‹è¼‰ç¯„åœå°æ‡‰æ¬„ä½ã€‚\n",
    "Sentinel Hubæä¾›ä½¿ç”¨è€…ä¸‹è¼‰ç©ºé–“è§£æåº¦ç‚ºæ¯åƒç´  10Ã—10mã€æœ€å¤§å°ºå¯¸ 2500Ã—2500 åƒç´ çš„å–®ä¸€å½±åƒæª”æ¡ˆã€‚\n",
    "è‹¥ç„¡éœ€å°‡æ¯å€‹æ¨£å€ä¹‹SARåœ–å±¤åˆ†åˆ¥å­˜å–ï¼Œä¸”å®Œæ•´ç›£æ¸¬ç¯„åœå°æ–¼ 25,000Ã—25,000mï¼Œ\n",
    "å¯å°‡æ‰€æœ‰ç›£æ¸¬ç¯„åœæ¶µè“‹æ–¼å–®ä¸€polygonä¸­ï¼Œä¸‹è¼‰ä¸€å¼µå½±åƒå³å¯ã€‚\n",
    "\"\"\"\n",
    "polygons_path = 'ç›£æ¸¬ç¯„åœåç¨±åŠè·¯å¾‘'\n",
    "polygons = gpd.read_file(polygons_path)\n",
    "if polygons.crs != \"EPSG:4326\":  # å¦‚æœåæ¨™ç³»ä¸æ˜¯ EPSG:4326ï¼Œå‰‡é€²è¡Œè½‰æ›\n",
    "  polygons = polygons.to_crs(\"EPSG:4326\")\n",
    "polygons[\"ID\"] = polygons[\"name\"].astype(str) # å¡«å…¥ polygon åç¨±æ¬„\n",
    "\n",
    "# è¨ˆç®—æ¯å€‹ polygon çš„é•·å¯¬\n",
    "polygons_m = polygons.to_crs(epsg=3826)\n",
    "bounds = polygons_m.bounds\n",
    "polygons[\"width_10m\"] = (bounds[\"maxx\"] - bounds[\"minx\"]) / 10\n",
    "polygons[\"height_10m\"] = (bounds[\"maxy\"] - bounds[\"miny\"]) / 10\n",
    "\n",
    "# å»ºç«‹æ¯å€‹ polygon çš„ bbox åº§æ¨™ (EPSG:4326)\n",
    "polygons[\"bbox_coords\"] = polygons.geometry.apply(\n",
    "    lambda g: [[\n",
    "        [g.bounds[0], g.bounds[1]],\n",
    "        [g.bounds[0], g.bounds[3]],\n",
    "        [g.bounds[2], g.bounds[3]],\n",
    "        [g.bounds[2], g.bounds[1]],\n",
    "        [g.bounds[0], g.bounds[1]]\n",
    "    ]]\n",
    ")\n",
    "\n",
    "print(f\"ğŸ—ºï¸ å·²è®€å– {len(polygons)} å€‹ç›£æ¸¬ç¯„åœ\")\n",
    "\n",
    "# === è¡›æ˜Ÿå½±åƒä¸‹è¼‰é€±æœŸ ===\n",
    "\"\"\"\n",
    "1. èµ·å§‹æ—¥(date_from)è«‹æŸ¥æ˜è¡›æ˜Ÿæ‹æ”æ—¥ï¼Œå¡«å…¥ã€ŒUTC+0ã€ä¹‹æ—¥æœŸã€‚\n",
    "2. è‹¥åƒ…éœ€å–®å¤©å½±åƒï¼ŒçµæŸæ—¥(date_until)èˆ‡èµ·å§‹æ—¥ç›¸åŒå³å¯ã€‚\n",
    "3. Sentinel-1è‡³ä»Šå…±ç™¼å°„ä¸‰é¡†ä»»å‹™è¡›æ˜Ÿï¼Œå–®é¡†è¡›æ˜Ÿå½±åƒé€±æœŸç‚º12æ—¥ï¼Œé è¨­é€±æœŸç‚º6æˆ–12æ—¥ä¸‹è¼‰ä¸€çµ„å½±åƒã€‚\n",
    "(S1A 2014è‡³ä»Šï¼›S1B 2016è‡³2022ï¼›S1C 2025/03/25èµ·æä¾›å°ç£å€å½±åƒï¼Œä»»å‹™æœŸç¨‹è©³æƒ…è«‹åƒè€ƒï¼š\n",
    "https://sentiwiki.copernicus.eu/web/s1-missionï¼‰\n",
    "\"\"\"\n",
    "date_from = datetime(2025, 10, 14)   # èµ·å§‹æ—¥ (UTC+0)\n",
    "date_until = datetime(2025, 10, 14)  # çµæŸæ—¥ (UTC+0)\n",
    "date_range = (date_until - date_from).days + 1 # å€é–“æ—¥æ•¸\n",
    "print(f\"â³ å°‡ä¸‹è¼‰ {date_range} å¤©ç¯„åœå…§çš„å½±åƒ\")\n",
    "\n",
    "oauth = loadtoken()\n",
    "\n",
    "for d in range(0, date_range, 6):  # è¨­å®šè¡›æ˜Ÿé€±æœŸå¤©æ•¸\n",
    "    new_dt = date_from + timedelta(days=d)  # (UTC+0)\n",
    "    new_dt_tw = new_dt + timedelta(days=1)  # å°æ‡‰çš„å°ç£æ™‚é–“ã€€(UTC+8)\n",
    "    for index, region in polygons.iterrows():\n",
    "        polygon = region[\"bbox_coords\"] # ä¸‹è¼‰æ¶µè“‹polygonä¹‹å®Œæ•´çŸ©å½¢åƒç´ æ•¸å€¼\n",
    "        # polygon = [list(region.geometry.exterior.coords)] # åƒ…ä¸‹è¼‰polygonç¯„åœåƒç´ æ•¸å€¼(èˆ‡å‰é …æ“‡ä¸€ä½¿ç”¨)\n",
    "        target = f\"S1_DV_SouthwestTaiwan_{new_dt_tw.strftime('%Y-%m-%d')}_{region['ID']}\" # å¡«å…¥ polygon åç¨±æ¬„\n",
    "        width = region[\"width_10m\"]\n",
    "        height = region[\"height_10m\"]\n",
    "        requestdata(polygon, target, width, height, new_dt, \"image\")\n",
    "\n",
    "\n",
    "print(\"\\nğŸ‰ å…¨éƒ¨å½±åƒä¸‹è¼‰å®Œæˆï¼\")\n",
    "print(f\"ğŸ“ è¼¸å‡ºè·¯å¾‘ï¼š{geotiff_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 18820,
     "status": "ok",
     "timestamp": 1762162314607,
     "user": {
      "displayName": "mickey Wu",
      "userId": "17857565069847384916"
     },
     "user_tz": -480
    },
    "id": "EE-jTHRFsUYQ",
    "outputId": "b279c499-194d-4fb1-888a-77aad4dcd97f"
   },
   "outputs": [],
   "source": [
    "# @title Part 2 - è¡›æ˜Ÿå½±åƒæ¥åˆ\n",
    "\"\"\"\n",
    "å¦‚æœç›£æ¸¬ç¯„åœå¯¬ã€é«˜å¤§æ–¼25å…¬é‡Œï¼Œå¿…é ˆå°‡å½±åƒåˆ‡å‰²å¾Œï¼Œæ–¹èƒ½ä¸‹è¼‰ã€‚\n",
    "è‹¥æ¨£å€å¯èƒ½é­è£åˆ‡æ–¼å¤šå¼µå½±åƒä¸­ï¼Œå°‡é€ æˆå¾ŒçºŒæ°´åŸŸè¨ˆç®—æœ‰èª¤ï¼Œå»ºè­°å°‡å½±åƒæ¥åˆå¾Œæ–¹èƒ½é€²è¡Œé‹ç®—ã€‚\n",
    "\"\"\"\n",
    "# === é€£æ¥ Google Drive ===\n",
    "\"\"\"\n",
    "æˆ‘å€‘ä½¿ç”¨ Google Drive ä½œç‚ºè¡›æ˜Ÿå½±åƒåŠåœ°ç†ç©ºé–“è³‡è¨Šå­˜å–è·¯å¾‘ï¼Œ\n",
    "æ•…é ˆå…ˆé€£çµä½¿ç”¨è€…Google Driveå¸³è™Ÿä»¥åŸ·è¡Œå¾ŒçºŒä½œæ¥­ã€‚\n",
    "\"\"\"\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "\n",
    "# === è¼‰å…¥æ‰€éœ€å¥—ä»¶ ===\n",
    "!pip install gdal\n",
    "import glob, os\n",
    "from osgeo import gdal\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "# === åŒ¯å…¥è¡›æ˜Ÿå½±åƒ ===\n",
    "geotiff_path = 'è¡›æ˜Ÿå½±åƒè·¯å¾‘'\n",
    "geotiff = [\n",
    "    os.path.join(geotiff_path, f)\n",
    "    for f in os.listdir(geotiff_path)\n",
    "    if f.lower().endswith(('.tif', '.tiff'))\n",
    "    ]\n",
    "\n",
    "\n",
    "# === æŒ‰æ—¥æœŸåˆ†çµ„ ===\n",
    "date_grouped_files = defaultdict(list)\n",
    "for file in geotiff:\n",
    "    base_name = os.path.basename(file)\n",
    "    date_part = \"_\".join(base_name.split(\"_\")[3:4])  # æå–æ—¥æœŸéƒ¨åˆ†\n",
    "    date_grouped_files[date_part].append(file)\n",
    "\n",
    "\n",
    "# === é€æ—¥æœŸåˆä½µå½±åƒ ===\n",
    "for date, files in date_grouped_files.items():\n",
    "    print(f\"æ­£åœ¨åˆä½µæ—¥æœŸ {date} çš„å½±åƒï¼š{files}ï¼Œå…± {len(files)} å¼µ\")\n",
    "    output_file = os.path.join(geotiff_path, f\"S1_DV_SouthwestTaiwan_{date}_merge.tif\")\n",
    "    vrt_options = gdal.BuildVRTOptions(srcNodata=0) # ä½¿ç”¨ gdal.BuildVRT ä¾†åˆä½µå½±åƒï¼Œè¨­å®š NoData ç‚º 0\n",
    "    vrt = gdal.BuildVRT(\"/vsimem/temp.vrt\", files, options=vrt_options)  # åœ¨è¨˜æ†¶é«”ä¸­å»ºç«‹ VRT\n",
    "    gdal.Translate(output_file, vrt, format=\"GTiff\") # è½‰æ› VRT ç‚º GeoTIFF\n",
    "    vrt = None # é‡‹æ”¾ VRT è¨˜æ†¶é«”\n",
    "    print(f\"åˆä½µå®Œæˆï¼Œè¼¸å‡ºæ–‡ä»¶ä¿å­˜ç‚ºï¼š{output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7752,
     "status": "ok",
     "timestamp": 1762157504936,
     "user": {
      "displayName": "mickey Wu",
      "userId": "17857565069847384916"
     },
     "user_tz": -480
    },
    "id": "IRBbdjOlCETv",
    "outputId": "7a1b0c2f-f7c0-48f8-8d02-1bb66c655923"
   },
   "outputs": [],
   "source": [
    "# @title Part 3 - æ°´åŸŸè¦†è“‹ç‡ç›£æ¸¬\n",
    "\n",
    "# === é€£æ¥ Google Drive ===\n",
    "\"\"\"\n",
    "æˆ‘å€‘ä½¿ç”¨ Google Drive ä½œç‚ºè¡›æ˜Ÿå½±åƒåŠåœ°ç†ç©ºé–“è³‡è¨Šå­˜å–è·¯å¾‘ï¼Œ\n",
    "æ•…é ˆå…ˆé€£çµä½¿ç”¨è€…Google Driveå¸³è™Ÿä»¥åŸ·è¡Œå¾ŒçºŒä½œæ¥­ã€‚\n",
    "\"\"\"\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "\n",
    "# === è¼‰å…¥æ‰€éœ€å¥—ä»¶ ===\n",
    "!pip install -q rasterio\n",
    "import os, rasterio\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "from rasterio.mask import mask\n",
    "from rasterio import features\n",
    "from shapely.geometry import shape, box\n",
    "from scipy.ndimage import binary_dilation\n",
    "\n",
    "# === åŒ¯å…¥è¡›æ˜Ÿå½±åƒåŠç›£æ¸¬polygon ===\n",
    "geotiff_path = 'è¡›æ˜Ÿå½±åƒè·¯å¾‘'\n",
    "\"\"\"\n",
    "geotiff = [\n",
    "    os.path.join(geotiff_path, f)\n",
    "    for f in os.listdir(geotiff_path)\n",
    "    if f.lower().endswith(('.tif', '.tiff'))\n",
    "    ]\n",
    "\"\"\"\n",
    "# è‹¥æƒ³æœå°‹ç‰¹å®šæª”åå¯æ”¹ç”¨é€™æ®µç¨‹å¼ç¢¼\n",
    "target = \"merge\"\n",
    "geotiff = [\n",
    "    os.path.join(geotiff_path, f)\n",
    "    for f in os.listdir(geotiff_path)\n",
    "    if f.lower().endswith(('.tif', '.tiff')) and target in f\n",
    "]\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "ä¸Šå‚³ GPKG æˆ– SHP (in EPSG:4326) ç›£æ¸¬ç¯„åœæª”æ¡ˆï¼Œ\n",
    "æª”æ¡ˆé ˆæœ‰ä¸€è­˜åˆ¥å„polygonçš„åç¨±æ¬„(å¦‚\"ID\"ã€\"name\")ï¼Œä½œç‚ºç›£æ¸¬ç¯„åœå°æ‡‰æ¬„ä½ã€‚\n",
    "\"\"\"\n",
    "polygons_path = 'ç›£æ¸¬ç¯„åœåç¨±åŠè·¯å¾‘'\n",
    "gdf = gpd.read_file(polygons_path)\n",
    "if gdf.crs != \"EPSG:4326\":\n",
    "  gdf = gdf.to_crs(\"EPSG:4326\")\n",
    "\n",
    "# ç¯©é¸æœ‰äº¤é›†å½±åƒ\n",
    "gdf_box = box(*gdf.total_bounds)\n",
    "geotiff_filtered = []\n",
    "for tif_path in geotiff:\n",
    "    with rasterio.open(tif_path) as src:\n",
    "        if box(*src.bounds).intersects(gdf_box):\n",
    "            geotiff_filtered.append(tif_path)\n",
    "print(f\"ğŸ—ºï¸ ç¯©é¸å¾Œå…± {len(geotiff_filtered)} ç­†å½±åƒåŒ…å«ç›£æ¸¬ç¯„åœ\")\n",
    "\n",
    "\n",
    "# === è¨ˆç®—æ°´åŸŸè¦†è“‹ç‡ ===\n",
    "# æŒ‡å®šæ¥µåŒ–åŠé–¾å€¼\n",
    "threshold = 0.029\n",
    "\n",
    "# æš«å­˜æ¯å€‹ polygon çš„çµæœ\n",
    "records = []\n",
    "\n",
    "# è¡›æ˜Ÿå½±åƒåˆ¤é‡‹è¿´åœˆ\n",
    "for geotifffile in geotiff_filtered:\n",
    "    try:\n",
    "        with rasterio.open(geotifffile) as src:\n",
    "            filename = os.path.basename(geotifffile)\n",
    "\n",
    "            # å˜—è©¦å¾æª”åæå–æ—¥æœŸè³‡è¨Š\n",
    "            try:\n",
    "                date_part = next((\n",
    "                    p for p in filename.split('_')\n",
    "                    if '-' in p and len(p.split('-')) == 3), None)\n",
    "                if date_part:\n",
    "                    year, month, day = date_part.split('-')\n",
    "                else:\n",
    "                    raise ValueError(\"æœªåµæ¸¬åˆ°æ—¥æœŸæ ¼å¼\")\n",
    "            except Exception:\n",
    "                print(f\"Skipping file {filename} â€” ç„¡æ³•è§£ææ—¥æœŸæ ¼å¼\")\n",
    "                continue\n",
    "\n",
    "            # é€ä¸€è™•ç†æ¯å€‹ polygon\n",
    "            for idx, row in gdf.iterrows():\n",
    "                b = {\"YEAR\": year, \"MONTH\": month, \"DAY\": day}\n",
    "                b['ID'] = row.get('ID', None) # å¡«å…¥ polygon åç¨±æ¬„\n",
    "                b['class'] = row.get('class', None)\n",
    "                \"\"\"\n",
    "                è‹¥éœ€è¦ä¿ç•™å…¶ä»–æ¬„ä½ï¼Œå¯åœ¨æ­¤æ–°å¢ï¼Œä¾‹å¦‚ï¼š\n",
    "                b['WATERTYPE'] = row.get('WATERTYPE', None)\n",
    "                b['GFISH'] = row.get('GFISH', None)\n",
    "                b['area'] = row.get('area', None)\n",
    "                \"\"\"\n",
    "                try:\n",
    "                    # ä½¿ç”¨ polygon å¹¾ä½•ç¯„åœé®ç½©\n",
    "                    out_image, out_transform = mask(\n",
    "                        src,\n",
    "                        [row.geometry],\n",
    "                        crop=True,\n",
    "                        filled=False,\n",
    "                        all_touched=True\n",
    "                    )\n",
    "\n",
    "                    # æå– VV æ¥µåŒ–æ•¸å€¼ (band 0)\n",
    "                    band = out_image[0]\n",
    "\n",
    "                    # å»ºç«‹ polygon é‚Šç•Œ maskï¼Œå½¢æˆå…§éƒ¨èˆ‡é‚Šç•Œå€åŸŸ\n",
    "                    polygon_mask = rasterio.features.geometry_mask(\n",
    "                        [row.geometry],\n",
    "                        transform=out_transform,\n",
    "                        invert=True,\n",
    "                        out_shape=band.shape\n",
    "                        )\n",
    "                    boundary_mask = rasterio.features.geometry_mask(\n",
    "                        [row.geometry.boundary],\n",
    "                        transform=out_transform,\n",
    "                        invert=True,\n",
    "                        out_shape=band.shape,\n",
    "                        all_touched=True\n",
    "                    )\n",
    "                    internal_mask = polygon_mask & (~boundary_mask)\n",
    "\n",
    "                    # æ°´åŸŸè¦†è“‹ç‡çµ±è¨ˆ\n",
    "                    boundary_data = band[boundary_mask]\n",
    "                    boundary_pixels = boundary_data.size\n",
    "                    internal_data = band[internal_mask]\n",
    "                    internal_pixels = internal_data.size\n",
    "                    internal_water_pixels = np.sum(internal_data <= threshold)\n",
    "                    water_ratio = internal_water_pixels / internal_pixels if internal_pixels > 0 else np.nan\n",
    "\n",
    "                    b.update({\n",
    "                        'boundary_pixel': boundary_pixels,\n",
    "                        'internal_pixel': internal_pixels,\n",
    "                        'internal_water_pixel': internal_water_pixels,\n",
    "                        'water_ratio': water_ratio\n",
    "                    })\n",
    "                    records.append(b)\n",
    "\n",
    "                except Exception as e:\n",
    "                    # print(f\"âš ï¸ Polygon {b.get('ID', 'æœªçŸ¥')} in {filename} ç™¼ç”ŸéŒ¯èª¤ï¼š{type(e).__name__} â€” {e}\")\n",
    "                    continue\n",
    "\n",
    "    except rasterio.errors.RasterioIOError as e:\n",
    "        print(f\"âš ï¸ ç„¡æ³•é–‹å•Ÿæª”æ¡ˆ {geotifffile}ï¼š{e}\")\n",
    "        continue\n",
    "\n",
    "\n",
    "# === åŒ¯å‡ºçµæœ ===\n",
    "df_vv = pd.DataFrame(records)\n",
    "output_csv_path = 'åŒ¯å‡ºåç¨±åŠè·¯å¾‘'\n",
    "os.makedirs(os.path.dirname(output_csv_path), exist_ok=True)\n",
    "df_vv.to_csv(output_csv_path, index=False, encoding='utf-8-sig')\n",
    "\n",
    "print(\"\\nâœ… æ°´åŸŸè¦†è“‹ç‡åˆ†æå®Œæˆï¼\")\n",
    "print(f\"ğŸ“ è¼¸å‡ºè·¯å¾‘ï¼š{output_csv_path}\")\n",
    "print(f\"ğŸ—‚ï¸ å…±åŒ¯å‡º {len(df_vv)} ç­†ç´€éŒ„ï¼ŒåŒ…å« {df_vv['ID'].nunique()} å€‹ç›£æ¸¬å€åŸŸã€‚\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMbgHQw7aGzWhlAY4b0b43N",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
